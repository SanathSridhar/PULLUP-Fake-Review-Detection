{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96dbae34-eebf-4d54-baaf-9cdb1a016313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/12/dd/f17b11a93a9ca27728e12512d167eb1281c151c4c6881d3ab59eb58f4127/transformers-4.35.2-py3-none-any.whl.metadata\n",
      "  Using cached transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.4)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/05/09/1945ca6ba3ad8ad6e2872ba682ce8d68c5e63c8e55458ed8ab4885709f1d/huggingface_hub-0.19.4-py3-none-any.whl.metadata\n",
      "  Using cached huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Obtaining dependency information for regex!=2019.12.17 from https://files.pythonhosted.org/packages/8f/3e/4b8b40eb3c80aeaf360f0361d956d129bb3d23b2a3ecbe3a04a8f3bdd6d3/regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
      "  Obtaining dependency information for tokenizers<0.19,>=0.14 from https://files.pythonhosted.org/packages/eb/3d/eee5f3c572a3f4db2ebabf5bd4f284f356078a5b5d27e6229b4450d5c5e4/tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Obtaining dependency information for safetensors>=0.3.1 from https://files.pythonhosted.org/packages/35/8f/892d2e1bcfceb7ee3f9b055ac4bb111e31d25f0a38c7f44d1d59bf7a501a/safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
      "Using cached transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
      "Using cached huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
      "Using cached regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "Using cached safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Using cached tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "Installing collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.19.4 regex-2023.10.3 safetensors-0.4.1 tokenizers-0.15.0 transformers-4.35.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8300d5be-17f0-4a7e-8e0d-2649bdb0524f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>review_links</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wsFRDsHxz2mM_Ettgn1qQg</td>\n",
       "      <td>x8ErSBur0SsnL1lZwP5o4Q</td>\n",
       "      <td>qf4LecJDQWIt0gt6VJWFPw</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>We got diverted to Tampa and decided to make t...</td>\n",
       "      <td>2017-06-28 01:07:04</td>\n",
       "      <td>https://www.yelp.com/biz/qf4LecJDQWIt0gt6VJWFP...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fg6B-QCi9IE9NfUQufFfNQ</td>\n",
       "      <td>tYVgGWTevie6UTMyINC3kw</td>\n",
       "      <td>M2ZrrqseHE5xssUrOL0Gtg</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quick&amp; friendly service, great portion size fo...</td>\n",
       "      <td>2015-12-20 22:15:00</td>\n",
       "      <td>https://www.yelp.com/biz/M2ZrrqseHE5xssUrOL0Gt...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L3MXURl5Uh5AGHbIeln14g</td>\n",
       "      <td>5pY-0Jw_qHxOgLeU3iyaGw</td>\n",
       "      <td>aKOdfQcjDG2NQtIEmq21ew</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Being from Cincinnati we know ipas and urban s...</td>\n",
       "      <td>2018-06-26 19:12:30</td>\n",
       "      <td>https://www.yelp.com/biz/aKOdfQcjDG2NQtIEmq21e...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8UwvPwoMzoyJIV6Wd5hZbg</td>\n",
       "      <td>157pNZAX0otHcMi0doqmqA</td>\n",
       "      <td>a7FSs8soBoxfkPXvzSsvbg</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Swung by here while I was in town and was so h...</td>\n",
       "      <td>2011-07-28 13:32:47</td>\n",
       "      <td>https://www.yelp.com/biz/a7FSs8soBoxfkPXvzSsvb...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSV_FqBhazt_R4q-JOqbdQ</td>\n",
       "      <td>nnXNbPjckCCFUE5JwnQj0A</td>\n",
       "      <td>SheKIt6Z_h-yzbkU8yjoPA</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nothing has changed since my last review. Thei...</td>\n",
       "      <td>2017-09-20 15:09:28</td>\n",
       "      <td>https://www.yelp.com/biz/SheKIt6Z_h-yzbkU8yjoP...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  wsFRDsHxz2mM_Ettgn1qQg  x8ErSBur0SsnL1lZwP5o4Q  qf4LecJDQWIt0gt6VJWFPw   \n",
       "1  Fg6B-QCi9IE9NfUQufFfNQ  tYVgGWTevie6UTMyINC3kw  M2ZrrqseHE5xssUrOL0Gtg   \n",
       "2  L3MXURl5Uh5AGHbIeln14g  5pY-0Jw_qHxOgLeU3iyaGw  aKOdfQcjDG2NQtIEmq21ew   \n",
       "3  8UwvPwoMzoyJIV6Wd5hZbg  157pNZAX0otHcMi0doqmqA  a7FSs8soBoxfkPXvzSsvbg   \n",
       "4  LSV_FqBhazt_R4q-JOqbdQ  nnXNbPjckCCFUE5JwnQj0A  SheKIt6Z_h-yzbkU8yjoPA   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      4       0      0     0   \n",
       "1      5       1      0     0   \n",
       "2      5       0      0     0   \n",
       "3      4       0      0     0   \n",
       "4      5       0      0     0   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0  We got diverted to Tampa and decided to make t...  2017-06-28 01:07:04   \n",
       "1  Quick& friendly service, great portion size fo...  2015-12-20 22:15:00   \n",
       "2  Being from Cincinnati we know ipas and urban s...  2018-06-26 19:12:30   \n",
       "3  Swung by here while I was in town and was so h...  2011-07-28 13:32:47   \n",
       "4  Nothing has changed since my last review. Thei...  2017-09-20 15:09:28   \n",
       "\n",
       "                                        review_links  label  \n",
       "0  https://www.yelp.com/biz/qf4LecJDQWIt0gt6VJWFP...    0.0  \n",
       "1  https://www.yelp.com/biz/M2ZrrqseHE5xssUrOL0Gt...    0.0  \n",
       "2  https://www.yelp.com/biz/aKOdfQcjDG2NQtIEmq21e...    0.0  \n",
       "3  https://www.yelp.com/biz/a7FSs8soBoxfkPXvzSsvb...    0.0  \n",
       "4  https://www.yelp.com/biz/SheKIt6Z_h-yzbkU8yjoP...    0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_test = pd.read_csv('review_dataset.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bad9871-f4e3-442a-b6ee-806428153b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1.0    4300\n",
       "0.0     700\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36377c9d-8d6a-4e6d-a23b-95e39fd19966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ClassifierFinal import ClassifierModel\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "test_texts = np.array(df_test['text'])\n",
    "test_texts_list = test_texts.tolist()\n",
    "test_labels = np.array(df_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b436e22b-c560-49f9-9436-a6a56144376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "inputs = test_tokenizer(test_texts_list, padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30c6b2db-be65-4956-b0bc-47c7e979ee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = torch.tensor(test_labels)\n",
    "test_dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'],test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7df83fa3-147e-42dd-af98-1d532c2fd30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ClassifierModel()\n",
    "model.load_state_dict(torch.load('classifier.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "326c7eae-aaf6-43f9-952d-a43fdee22793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierModel(\n",
       "  (bert_model): BertForSequenceClassification(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e2ed87-cefc-49dc-bebe-dbf7257b699e",
   "metadata": {},
   "source": [
    "<h2> Using Positive Unlabelled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ed4a7d0-2829-412c-94ce-933d229edfa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Score: 0.8131, Test Recall: 0.7674, Test Precision: 0.8646\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,recall_score,precision_score\n",
    "\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "true_labels = []\n",
    "threshold = 0.35\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_batch in  test_loader:\n",
    "        \n",
    "        test_input_ids, test_attention_mask, test_labels = test_batch\n",
    "        test_input_ids, test_attention_mask, test_labels = test_input_ids.to(device), test_attention_mask.to(device), test_labels.to(device)\n",
    "        test_outputs = model(test_input_ids, attention_mask=test_attention_mask)\n",
    "        predicted_class = (test_outputs[:,1] > threshold).float()\n",
    "        test_predictions.extend(predicted_class.cpu().numpy())\n",
    "        true_labels.extend(test_labels.cpu().numpy())\n",
    "\n",
    "test_f1 = f1_score(true_labels, test_predictions)\n",
    "test_recall = recall_score(true_labels, test_predictions)\n",
    "test_precision = precision_score(true_labels, test_predictions)\n",
    "print(f'Test F1 Score: {test_f1:.4f}, Test Recall: {test_recall:.4f}, Test Precision: {test_precision:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32977456-99c6-4a9d-8ffd-bd7f0637e18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 183  517]\n",
      " [1000 3300]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(true_labels,test_predictions )\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a512916f-2bf6-410b-a3e6-47d891007089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1183"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array(test_predictions) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edccb2c9-fd6e-4523-954c-eb840d57a671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Genuine:3817\n",
      "Number of Fake:1183\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Genuine:\"+str(np.sum(np.array(test_predictions) == 1)))\n",
    "print(\"Number of Fake:\"+str(np.sum(np.array(test_predictions) == 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcc4fe5-5149-4c03-bbd8-fdd5d86924e8",
   "metadata": {},
   "source": [
    "<h2> Test on Unseen Restaurant Reviews Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd96ad37-9956-43e4-a48b-1f6d77160acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Real\n",
       "0    55\n",
       "1    55\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test2 = pd.read_csv('restaurant_reviews_anonymized.csv',encoding='latin-1')\n",
    "df_test2.Real.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9be8436-8b84-4247-b52d-3d45c2aa59f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts2 = np.array(df_test2['Review'])\n",
    "test_labels2 = np.array(df_test2['Real'])\n",
    "test_texts_list2 = test_texts2.tolist()\n",
    "inputs = test_tokenizer(test_texts_list2, padding=True, truncation=True, return_tensors='pt')\n",
    "labels2 = torch.tensor(test_labels2)\n",
    "test_dataset2 = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels2)\n",
    "test_loader2 = DataLoader(test_dataset2, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15c146bf-0ce9-481d-861a-8ad61e3f566f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Score: 0.5440, Test Recall: 0.6182, Test Precision: 0.4857\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_predictions = []\n",
    "true_labels = []\n",
    "\n",
    "threshold = 0.35 #Adjust the threshold as needed\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_batch in  test_loader2:\n",
    "        \n",
    "        test_input_ids, test_attention_mask, test_labels = test_batch\n",
    "        test_input_ids, test_attention_mask, test_labels = test_input_ids.to(device), test_attention_mask.to(device), test_labels.to(device)\n",
    "        test_outputs = model(test_input_ids, attention_mask=test_attention_mask)\n",
    "        predicted_class = (test_outputs[:,1] > threshold).float()\n",
    "        test_predictions.extend(predicted_class.cpu().numpy())\n",
    "        true_labels.extend(test_labels.cpu().numpy())\n",
    "\n",
    "test_f1 = f1_score(true_labels, test_predictions)\n",
    "test_recall = recall_score(true_labels, test_predictions)\n",
    "test_precision = precision_score(true_labels, test_predictions)\n",
    "print(f'Test F1 Score: {test_f1:.4f}, Test Recall: {test_recall:.4f}, Test Precision: {test_precision:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e048169-47cc-4b0d-bcd0-9b8dfdb319ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[19 36]\n",
      " [21 34]]\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(true_labels,test_predictions )\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e1cdc65-debf-42b9-a7a5-4eb76053186a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Genuine:70\n",
      "Number of Fake:40\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Genuine:\"+str(np.sum(np.array(test_predictions) == 1)))\n",
    "print(\"Number of Fake:\"+str(np.sum(np.array(test_predictions) == 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a91999-3eb3-40ad-9389-bc9c52b3cd9b",
   "metadata": {},
   "source": [
    "<h2> Test on Unseen Hotel Review Data (Cross Domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3cd9ff92-5157-4206-88b3-9557d6a8d332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deceptive\n",
       "1    800\n",
       "0    800\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test3 = pd.read_csv('deceptive-opinion.csv')\n",
    "label_mapping = {'deceptive': 0, 'truthful': 1}\n",
    "df_test3['deceptive'] = df_test3['deceptive'].map(label_mapping)\n",
    "df_test3.deceptive.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6f8af41-9509-4aec-8913-b6b6ba0ec964",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts3 = np.array(df_test3['text'])\n",
    "test_labels3 = np.array(df_test3['deceptive'])\n",
    "test_texts_list3 = test_texts3.tolist()\n",
    "inputs = test_tokenizer(test_texts_list3, padding=True, truncation=True, return_tensors='pt')\n",
    "labels3 = torch.tensor(test_labels3)\n",
    "test_dataset3 = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels3)\n",
    "test_loader3 = DataLoader(test_dataset3, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b4290fe5-1934-458b-9909-be960949e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Score: 0.6057, Test Recall: 0.7863, Test Precision: 0.4926\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_predictions = []\n",
    "true_labels = []\n",
    "\n",
    "threshold = 0.35 #Adjust the threshold as needed\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_batch in  test_loader3:\n",
    "        \n",
    "        test_input_ids, test_attention_mask, test_labels = test_batch\n",
    "        test_input_ids, test_attention_mask, test_labels = test_input_ids.to(device), test_attention_mask.to(device), test_labels.to(device)\n",
    "        test_outputs = model(test_input_ids, attention_mask=test_attention_mask)\n",
    "        predicted_class = (test_outputs[:,1] > threshold).float()\n",
    "        test_predictions.extend(predicted_class.cpu().numpy())\n",
    "        true_labels.extend(test_labels.cpu().numpy())\n",
    "\n",
    "test_f1 = f1_score(true_labels, test_predictions)\n",
    "test_recall = recall_score(true_labels, test_predictions)\n",
    "test_precision = precision_score(true_labels, test_predictions)\n",
    "print(f'Test F1 Score: {test_f1:.4f}, Test Recall: {test_recall:.4f}, Test Precision: {test_precision:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "257fe49f-08d1-4631-8f82-b33ef8d3aca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[152 648]\n",
      " [171 629]]\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(true_labels,test_predictions )\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "63da2b1d-fe73-4eb5-9618-5a4a76258d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Genuine:1277\n",
      "Number of Fake:323\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Genuine:\"+str(np.sum(np.array(test_predictions) == 1)))\n",
    "print(\"Number of Fake:\"+str(np.sum(np.array(test_predictions) == 0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.0 (Local)",
   "language": "python",
   "name": "local-pytorch-2-0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
